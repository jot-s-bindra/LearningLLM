{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate<1,>=0.16.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (0.24.1)\n",
      "Collecting transformers<5,>=4.28.1 (from transformers[torch]<5,>=4.28.1)\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch<2,>=1.13.1\n",
      "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from accelerate<1,>=0.16.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from accelerate<1,>=0.16.0) (23.2)\n",
      "Requirement already satisfied: psutil in /home/outbreakkp/.local/lib/python3.10/site-packages (from accelerate<1,>=0.16.0) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/outbreakkp/.local/lib/python3.10/site-packages (from accelerate<1,>=0.16.0) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/outbreakkp/.local/lib/python3.10/site-packages (from accelerate<1,>=0.16.0) (0.18.0)\n",
      "Requirement already satisfied: filelock in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (3.12.4)\n",
      "Collecting huggingface-hub (from accelerate<1,>=0.16.0)\n",
      "  Downloading huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1)\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch<2,>=1.13.1) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch<2,>=1.13.1) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch<2,>=1.13.1) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch<2,>=1.13.1) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch<2,>=1.13.1) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2,>=1.13.1) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2,>=1.13.1) (0.37.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate<1,>=0.16.0) (2023.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->transformers<5,>=4.28.1->transformers[torch]<5,>=4.28.1) (2023.7.22)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu, huggingface-hub, torch, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.18.0\n",
      "    Uninstalling huggingface-hub-0.18.0:\n",
      "      Successfully uninstalled huggingface-hub-0.18.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.2\n",
      "    Uninstalling transformers-4.27.2:\n",
      "      Successfully uninstalled transformers-4.27.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0 requires torch==2.1.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed faiss-cpu-1.7.4 huggingface-hub-0.20.1 tokenizers-0.15.0 torch-1.13.1 transformers-4.36.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in /home/outbreakkp/.local/lib/python3.10/site-packages (3.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /home/outbreakkp/.local/lib/python3.10/site-packages (0.0.352)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (0.0.6)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (0.1.3)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (0.0.74)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (2.5.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/outbreakkp/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/outbreakkp/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/outbreakkp/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/outbreakkp/.local/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /home/outbreakkp/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/outbreakkp/.local/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/outbreakkp/.local/lib/python3.10/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence_transformers in /home/outbreakkp/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (0.20.1)\n",
      "Requirement already satisfied: nltk in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: scipy in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (1.11.3)\n",
      "Requirement already satisfied: sentencepiece in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (0.16.0)\n",
      "Requirement already satisfied: tqdm in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from sentence_transformers) (4.36.2)\n",
      "Requirement already satisfied: filelock in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.9.2)\n",
      "Requirement already satisfied: requests in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/outbreakkp/.local/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers) (0.37.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: click in /home/outbreakkp/.local/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/outbreakkp/.local/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Collecting torch>=1.6.0 (from sentence_transformers)\n",
      "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torchvision->sentence_transformers) (10.0.1)\n",
      "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch>=1.6.0->sentence_transformers) (1.9)\n",
      "Requirement already satisfied: networkx in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/outbreakkp/.local/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/outbreakkp/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/outbreakkp/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.5.1 requires torch==1.13.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install \"accelerate>=0.16.0,<1\" \"transformers[torch]>=4.28.1,<5\" \"torch>=1.13.1,<2\" faiss-cpu\n",
    "!pip install PyPDF2\n",
    "!pip install langchain\n",
    "!pip install transformers\n",
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import PyPDF2\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-Net: Convolutional Networks for Biomedical\n",
      "Image Segmentation\n",
      "Olaf Ronneberger, Philipp Fischer, and Thomas Brox\n",
      "Computer Science Department and BIOSS Centre for Biological Signalling Studies,\n",
      "University of Freiburg, Germany\n",
      "ronneber@informatik.uni-freiburg.de ,\n",
      "WWW home page: http://lmb.informatik.uni-freiburg.de/\n",
      "Abstract. There is large consent that successful training of deep net-\n",
      "works requires many thousand annotated training samples. In this pa-\n",
      "per, we present a network and training strategy that relies on the strong\n",
      "use of data augmentation to use the available annotated samples more\n",
      "e\u000eciently. The architecture consists of a contracting path to capture\n",
      "context and a symmetric expanding path that enables precise localiza-\n",
      "tion. We show that such a network can be trained end-to-end from very\n",
      "few images and outperforms the prior best method (a sliding-window\n",
      "convolutional network) on the ISBI challenge for segmentation of neu-\n",
      "ronal structures in electron microscopic stacks. Using the same net-\n",
      "work trained on transmitted light microscopy images (phase contrast\n",
      "and DIC) we won the ISBI cell tracking challenge 2015 in these cate-\n",
      "gories by a large margin. Moreover, the network is fast. Segmentation\n",
      "of a 512x512 image takes less than a second on a recent GPU. The full\n",
      "implementation (based on Ca\u000be) and the trained networks are available\n",
      "at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.\n",
      "1 Introduction\n",
      "In the last two years, deep convolutional networks have outperformed the state of\n",
      "the art in many visual recognition tasks, e.g. [7,3]. While convolutional networks\n",
      "have already existed for a long time [8], their success was limited due to the\n",
      "size of the available training sets and the size of the considered networks. The\n",
      "breakthrough by Krizhevsky et al. [7] was due to supervised training of a large\n",
      "network with 8 layers and millions of parameters on the ImageNet dataset with\n",
      "1 million training images. Since then, even larger and deeper networks have been\n",
      "trained [12].\n",
      "The typical use of convolutional networks is on classi\fcation tasks, where\n",
      "the output to an image is a single class label. However, in many visual tasks,\n",
      "especially in biomedical image processing, the desired output should include\n",
      "localization, i.e., a class label is supposed to be assigned to each pixel. More-\n",
      "over, thousands of training images are usually beyond reach in biomedical tasks.\n",
      "Hence, Ciresan et al. [1] trained a network in a sliding-window setup to predict\n",
      "the class label of each pixel by providing a local region (patch) around that pixelarXiv:1505.04597v1  [cs.CV]  18 May 20152\n",
      "copy and cropinput\n",
      "image\n",
      "tileoutput \n",
      "segmentation \n",
      "map641\n",
      "128\n",
      "256\n",
      "512\n",
      "1024max pool 2x2\n",
      "up-conv 2x2conv 3x3, ReLU572 x 572\n",
      "284²64\n",
      "128\n",
      "256\n",
      "512570 x 570\n",
      "568 x 568\n",
      "282²\n",
      "280²140²\n",
      "138²\n",
      "136²68²\n",
      "66²\n",
      "64²32²\n",
      "28²56²\n",
      "54²\n",
      "52²512\n",
      "104²\n",
      "102²\n",
      "100²200²30²\n",
      "198²\n",
      "196²392 x 392\n",
      "390 x 390\n",
      "388 x 388\n",
      "388 x 388\n",
      "102451225625612864128642\n",
      "conv 1x1\n",
      "Fig. 1. U-net architecture (example for 32x32 pixels in the lowest resolution). Each blue\n",
      "box corresponds to a multi-channel feature map. The number of channels is denoted\n",
      "on top of the box. The x-y-size is provided at the lower left edge of the box. White\n",
      "boxes represent copied feature maps. The arrows denote the di\u000berent operations.\n",
      "as input. First, this network can localize. Secondly, the training data in terms\n",
      "of patches is much larger than the number of training images. The resulting\n",
      "network won the EM segmentation challenge at ISBI 2012 by a large margin.\n",
      "Obviously, the strategy in Ciresan et al. [1] has two drawbacks. First, it\n",
      "is quite slow because the network must be run separately for each patch, and\n",
      "there is a lot of redundancy due to overlapping patches. Secondly, there is a\n",
      "trade-o\u000b between localization accuracy and the use of context. Larger patches\n",
      "require more max-pooling layers that reduce the localization accuracy, while\n",
      "small patches allow the network to see only little context. More recent approaches\n",
      "[11,4] proposed a classi\fer output that takes into account the features from\n",
      "multiple layers. Good localization and the use of context are possible at the\n",
      "same time.\n",
      "In this paper, we build upon a more elegant architecture, the so-called \\fully\n",
      "convolutional network\" [9]. We modify and extend this architecture such that it\n",
      "works with very few training images and yields more precise segmentations; see\n",
      "Figure 1. The main idea in [9] is to supplement a usual contracting network by\n",
      "successive layers, where pooling operators are replaced by upsampling operators.\n",
      "Hence, these layers increase the resolution of the output. In order to localize, high\n",
      "resolution features from the contracting path are combined with the upsampled3\n",
      "Fig. 2. Overlap-tile strategy for seamless segmentation of arbitrary large images (here\n",
      "segmentation of neuronal structures in EM stacks). Prediction of the segmentation in\n",
      "the yellow area, requires image data within the blue area as input. Missing input data\n",
      "is extrapolated by mirroring\n",
      "output. A successive convolution layer can then learn to assemble a more precise\n",
      "output based on this information.\n",
      "One important modi\fcation in our architecture is that in the upsampling\n",
      "part we have also a large number of feature channels, which allow the network\n",
      "to propagate context information to higher resolution layers. As a consequence,\n",
      "the expansive path is more or less symmetric to the contracting path, and yields\n",
      "a u-shaped architecture. The network does not have any fully connected layers\n",
      "and only uses the valid part of each convolution, i.e., the segmentation map only\n",
      "contains the pixels, for which the full context is available in the input image.\n",
      "This strategy allows the seamless segmentation of arbitrarily large images by an\n",
      "overlap-tile strategy (see Figure 2). To predict the pixels in the border region\n",
      "of the image, the missing context is extrapolated by mirroring the input image.\n",
      "This tiling strategy is important to apply the network to large images, since\n",
      "otherwise the resolution would be limited by the GPU memory.\n",
      "As for our tasks there is very little training data available, we use excessive\n",
      "data augmentation by applying elastic deformations to the available training im-\n",
      "ages. This allows the network to learn invariance to such deformations, without\n",
      "the need to see these transformations in the annotated image corpus. This is\n",
      "particularly important in biomedical segmentation, since deformation used to\n",
      "be the most common variation in tissue and realistic deformations can be simu-\n",
      "lated e\u000eciently. The value of data augmentation for learning invariance has been\n",
      "shown in Dosovitskiy et al. [2] in the scope of unsupervised feature learning.\n",
      "Another challenge in many cell segmentation tasks is the separation of touch-\n",
      "ing objects of the same class; see Figure 3. To this end, we propose the use of\n",
      "a weighted loss, where the separating background labels between touching cells\n",
      "obtain a large weight in the loss function.\n",
      "The resulting network is applicable to various biomedical segmentation prob-\n",
      "lems. In this paper, we show results on the segmentation of neuronal structures\n",
      "in EM stacks (an ongoing competition started at ISBI 2012), where we out-4\n",
      "performed the network of Ciresan et al. [1]. Furthermore, we show results for\n",
      "cell segmentation in light microscopy images from the ISBI cell tracking chal-\n",
      "lenge 2015. Here we won with a large margin on the two most challenging 2D\n",
      "transmitted light datasets.\n",
      "2 Network Architecture\n",
      "The network architecture is illustrated in Figure 1. It consists of a contracting\n",
      "path (left side) and an expansive path (right side). The contracting path follows\n",
      "the typical architecture of a convolutional network. It consists of the repeated\n",
      "application of two 3x3 convolutions (unpadded convolutions), each followed by\n",
      "a recti\fed linear unit (ReLU) and a 2x2 max pooling operation with stride 2\n",
      "for downsampling. At each downsampling step we double the number of feature\n",
      "channels. Every step in the expansive path consists of an upsampling of the\n",
      "feature map followed by a 2x2 convolution (\\up-convolution\") that halves the\n",
      "number of feature channels, a concatenation with the correspondingly cropped\n",
      "feature map from the contracting path, and two 3x3 convolutions, each fol-\n",
      "lowed by a ReLU. The cropping is necessary due to the loss of border pixels in\n",
      "every convolution. At the \fnal layer a 1x1 convolution is used to map each 64-\n",
      "component feature vector to the desired number of classes. In total the network\n",
      "has 23 convolutional layers.\n",
      "To allow a seamless tiling of the output segmentation map (see Figure 2), it\n",
      "is important to select the input tile size such that all 2x2 max-pooling operations\n",
      "are applied to a layer with an even x- and y-size.\n",
      "3 Training\n",
      "The input images and their corresponding segmentation maps are used to train\n",
      "the network with the stochastic gradient descent implementation of Ca\u000be [6].\n",
      "Due to the unpadded convolutions, the output image is smaller than the input\n",
      "by a constant border width. To minimize the overhead and make maximum use\n",
      "of the GPU memory, we favor large input tiles over a large batch size and hence\n",
      "reduce the batch to a single image. Accordingly we use a high momentum (0.99)\n",
      "such that a large number of the previously seen training samples determine the\n",
      "update in the current optimization step.\n",
      "The energy function is computed by a pixel-wise soft-max over the \fnal\n",
      "feature map combined with the cross entropy loss function. The soft-max is\n",
      "de\fned aspk(x) = exp(ak(x))=\u0010PK\n",
      "k0=1exp(ak0(x))\u0011\n",
      "whereak(x) denotes the\n",
      "activation in feature channel kat the pixel position x2\n",
      "with\n",
      "\u001aZ2.K\n",
      "is the number of classes and pk(x) is the approximated maximum-function. I.e.\n",
      "pk(x)\u00191 for thekthat has the maximum activation ak(x) andpk(x)\u00190 for\n",
      "all otherk. The cross entropy then penalizes at each position the deviation of\n",
      "p`(x)(x) from 1 using\n",
      "E=X\n",
      "x2\n",
      "w(x) log(p`(x)(x)) (1)5\n",
      "a\n",
      " b\n",
      " c\n",
      " d\n",
      "Fig. 3. HeLa cells on glass recorded with DIC (di\u000berential interference contrast) mi-\n",
      "croscopy. ( a) raw image. ( b) overlay with ground truth segmentation. Di\u000berent colors\n",
      "indicate di\u000berent instances of the HeLa cells. ( c) generated segmentation mask (white:\n",
      "foreground, black: background). ( d) map with a pixel-wise loss weight to force the\n",
      "network to learn the border pixels.\n",
      "where`:\n",
      "!f1;:::;Kgis the true label of each pixel and w:\n",
      "!Ris\n",
      "a weight map that we introduced to give some pixels more importance in the\n",
      "training.\n",
      "We pre-compute the weight map for each ground truth segmentation to com-\n",
      "pensate the di\u000berent frequency of pixels from a certain class in the training\n",
      "data set, and to force the network to learn the small separation borders that we\n",
      "introduce between touching cells (See Figure 3c and d).\n",
      "The separation border is computed using morphological operations. The\n",
      "weight map is then computed as\n",
      "w(x) =wc(x) +w0\u0001exp \n",
      "\u0000(d1(x) +d2(x))2\n",
      "2\u001b2!\n",
      "(2)\n",
      "wherewc:\n",
      "!Ris the weight map to balance the class frequencies, d1:\n",
      "!R\n",
      "denotes the distance to the border of the nearest cell and d2:\n",
      "!Rthe distance\n",
      "to the border of the second nearest cell. In our experiments we set w0= 10 and\n",
      "\u001b\u00195 pixels.\n",
      "In deep networks with many convolutional layers and di\u000berent paths through\n",
      "the network, a good initialization of the weights is extremely important. Oth-\n",
      "erwise, parts of the network might give excessive activations, while other parts\n",
      "never contribute. Ideally the initial weights should be adapted such that each\n",
      "feature map in the network has approximately unit variance. For a network with\n",
      "our architecture (alternating convolution and ReLU layers) this can be achieved\n",
      "by drawing the initial weights from a Gaussian distribution with a standard\n",
      "deviation ofp\n",
      "2=N, whereNdenotes the number of incoming nodes of one neu-\n",
      "ron [5]. E.g. for a 3x3 convolution and 64 feature channels in the previous layer\n",
      "N= 9\u000164 = 576.\n",
      "3.1 Data Augmentation\n",
      "Data augmentation is essential to teach the network the desired invariance and\n",
      "robustness properties, when only few training samples are available. In case of6\n",
      "microscopical images we primarily need shift and rotation invariance as well as\n",
      "robustness to deformations and gray value variations. Especially random elas-\n",
      "tic deformations of the training samples seem to be the key concept to train\n",
      "a segmentation network with very few annotated images. We generate smooth\n",
      "deformations using random displacement vectors on a coarse 3 by 3 grid. The\n",
      "displacements are sampled from a Gaussian distribution with 10 pixels standard\n",
      "deviation. Per-pixel displacements are then computed using bicubic interpola-\n",
      "tion. Drop-out layers at the end of the contracting path perform further implicit\n",
      "data augmentation.\n",
      "4 Experiments\n",
      "We demonstrate the application of the u-net to three di\u000berent segmentation\n",
      "tasks. The \frst task is the segmentation of neuronal structures in electron mi-\n",
      "croscopic recordings. An example of the data set and our obtained segmentation\n",
      "is displayed in Figure 2. We provide the full result as Supplementary Material.\n",
      "The data set is provided by the EM segmentation challenge [14] that was started\n",
      "at ISBI 2012 and is still open for new contributions. The training data is a set of\n",
      "30 images (512x512 pixels) from serial section transmission electron microscopy\n",
      "of the Drosophila \frst instar larva ventral nerve cord (VNC). Each image comes\n",
      "with a corresponding fully annotated ground truth segmentation map for cells\n",
      "(white) and membranes (black). The test set is publicly available, but its seg-\n",
      "mentation maps are kept secret. An evaluation can be obtained by sending the\n",
      "predicted membrane probability map to the organizers. The evaluation is done\n",
      "by thresholding the map at 10 di\u000berent levels and computation of the \\warping\n",
      "error\", the \\Rand error\" and the \\pixel error\" [14].\n",
      "The u-net (averaged over 7 rotated versions of the input data) achieves with-\n",
      "out any further pre- or postprocessing a warping error of 0.0003529 (the new\n",
      "best score, see Table 1) and a rand-error of 0.0382.\n",
      "This is signi\fcantly better than the sliding-window convolutional network\n",
      "result by Ciresan et al. [1], whose best submission had a warping error of 0.000420\n",
      "and a rand error of 0.0504. In terms of rand error the only better performing\n",
      "Table 1. Ranking on the EM segmentation challenge [14] (march 6th, 2015), sorted\n",
      "by warping error.\n",
      "Rank Group name Warping Error Rand Error Pixel Error\n",
      "** human values ** 0.000005 0.0021 0.0010\n",
      "1. u-net 0.000353 0.0382 0.0611\n",
      "2. DIVE-SCI 0.000355 0.0305 0.0584\n",
      "3. IDSIA [1] 0.000420 0.0504 0.0613\n",
      "4. DIVE 0.000430 0.0545 0.0582\n",
      "...\n",
      "10. IDSIA-SCI 0.000653 0.0189 0.10277\n",
      "a\n",
      " b\n",
      " c\n",
      " d\n",
      "Fig. 4. Result on the ISBI cell tracking challenge. ( a) part of an input image of the\n",
      "\\PhC-U373\" data set. ( b) Segmentation result (cyan mask) with manual ground truth\n",
      "(yellow border) ( c) input image of the \\DIC-HeLa\" data set. ( d) Segmentation result\n",
      "(random colored masks) with manual ground truth (yellow border).\n",
      "Table 2. Segmentation results (IOU) on the ISBI cell tracking challenge 2015.\n",
      "Name PhC-U373 DIC-HeLa\n",
      "IMCB-SG (2014) 0.2669 0.2935\n",
      "KTH-SE (2014) 0.7953 0.4607\n",
      "HOUS-US (2014) 0.5323 -\n",
      "second-best 2015 0.83 0.46\n",
      "u-net (2015) 0.9203 0.7756\n",
      "algorithms on this data set use highly data set speci\fc post-processing methods1\n",
      "applied to the probability map of Ciresan et al. [1].\n",
      "We also applied the u-net to a cell segmentation task in light microscopic im-\n",
      "ages. This segmenation task is part of the ISBI cell tracking challenge 2014 and\n",
      "2015 [10,13]. The \frst data set \\PhC-U373\"2contains Glioblastoma-astrocytoma\n",
      "U373 cells on a polyacrylimide substrate recorded by phase contrast microscopy\n",
      "(see Figure 4a,b and Supp. Material). It contains 35 partially annotated train-\n",
      "ing images. Here we achieve an average IOU (\\intersection over union\") of 92%,\n",
      "which is signi\fcantly better than the second best algorithm with 83% (see Ta-\n",
      "at glass recordedd data set \\DIC-HeLa\"3are HeLa cells on a \n",
      "by di\u000berential interference contrast (DIC) microscopy (see Figure 3, Figure 4c,d\n",
      "and Supp. Material). It contains 20 partially annotated training images. Here we\n",
      "achieve an average IOU of 77.5% which is signi\fcantly better than the second\n",
      "best algorithm with 46%.\n",
      "5 Conclusion\n",
      "The u-net architecture achieves very good performance on very di\u000berent biomed-\n",
      "ical segmentation applications. Thanks to data augmentation with elastic defor-\n",
      "1The authors of this algorithm have submitted 78 di\u000berent solutions to achieve this\n",
      "result.\n",
      "2Data set provided by Dr. Sanjay Kumar. Department of Bioengineering University\n",
      "of California at Berkeley. Berkeley CA (USA)\n",
      "3Data set provided by Dr. Gert van Cappellen Erasmus Medical Center. Rotterdam.\n",
      "The Netherlands8\n",
      "mations, it only needs very few annotated images and has a very reasonable\n",
      "training time of only 10 hours on a NVidia Titan GPU (6 GB). We provide the\n",
      "full Ca\u000be[6]-based implementation and the trained networks4. We are sure that\n",
      "the u-net architecture can be applied easily to many more tasks.\n",
      "Acknowlegements\n",
      "This study was supported by the Excellence Initiative of the German Federal\n",
      "and State governments (EXC 294) and by the BMBF (Fkz 0316185B).\n",
      "References\n",
      "1. Ciresan, D.C., Gambardella, L.M., Giusti, A., Schmidhuber, J.: Deep neural net-\n",
      "works segment neuronal membranes in electron microscopy images. In: NIPS. pp.\n",
      "2852{2860 (2012)\n",
      "2. Dosovitskiy, A., Springenberg, J.T., Riedmiller, M., Brox, T.: Discriminative un-\n",
      "supervised feature learning with convolutional neural networks. In: NIPS (2014)\n",
      "3. Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for ac-\n",
      "curate object detection and semantic segmentation. In: Proceedings of the IEEE\n",
      "Conference on Computer Vision and Pattern Recognition (CVPR) (2014)\n",
      "4. Hariharan, B., Arbelez, P., Girshick, R., Malik, J.: Hypercolumns for object seg-\n",
      "mentation and \fne-grained localization (2014), arXiv:1411.5752 [cs.CV]\n",
      "5. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into recti\fers: Surpassing human-\n",
      "level performance on imagenet classi\fcation (2015), arXiv:1502.01852 [cs.CV]\n",
      "6. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadar-\n",
      "rama, S., Darrell, T.: Ca\u000be: Convolutional architecture for fast feature embedding\n",
      "(2014), arXiv:1408.5093 [cs.CV]\n",
      "7. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classi\fcation with deep con-\n",
      "volutional neural networks. In: NIPS. pp. 1106{1114 (2012)\n",
      "8. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.,\n",
      "Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural\n",
      "Computation 1(4), 541{551 (1989)\n",
      "9. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic\n",
      "segmentation (2014), arXiv:1411.4038 [cs.CV]\n",
      "10. Maska, M., (...), de Solorzano, C.O.: A benchmark for comparison of cell tracking\n",
      "algorithms. Bioinformatics 30, 1609{1617 (2014)\n",
      "11. Seyedhosseini, M., Sajjadi, M., Tasdizen, T.: Image segmentation with cascaded\n",
      "hierarchical models and logistic disjunctive normal networks. In: Computer Vision\n",
      "(ICCV), 2013 IEEE International Conference on. pp. 2168{2175 (2013)\n",
      "12. Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale\n",
      "image recognition (2014), arXiv:1409.1556 [cs.CV]\n",
      "13. WWW: Web page of the cell tracking challenge, http://www.codesolorzano.com/\n",
      "celltrackingchallenge/Cell_Tracking_Challenge/Welcome.html\n",
      "14. WWW: Web page of the em segmentation challenge, http://brainiac2.mit.edu/\n",
      "isbi_challenge/\n",
      "4U-net implementation, trained networks and supplementary material available at\n",
      "http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net\n"
     ]
    }
   ],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name,use_fast=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "\n",
    "with open(\"U-Net.pdf\", \"rb\") as pdf_file:\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "print(text)\n",
    "\n",
    "# cleaned_text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "model_sbert = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "# embeddings = model_sbert.encode(cleaned_text.split(\".\"))\n",
    "embeddings = model_sbert.encode(text.split(\".\"))\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question):\n",
    "    query_embedding = model_sbert.encode([question])\n",
    "    distances, indices = index.search(query_embedding, k=5)\n",
    "\n",
    "    retrieved_text = [text.split(\".\")[i] for i in indices.flatten()]\n",
    "    retrieved_text_combined = \" \".join(retrieved_text)\n",
    "    # print(retrieved_text_combined)\n",
    "    input_ids = tokenizer(retrieved_text_combined, return_tensors=\"pt\")\n",
    "    # print(\"Input IDs:\", input_ids)\n",
    "    answer = model.generate(**input_ids,max_length=50)\n",
    "    return answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer to question 'explain Data Augmentation': We propose a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more eciently.\n"
     ]
    }
   ],
   "source": [
    "question = \"explain Data Augmentation\"\n",
    "answer = answer_question(question)\n",
    "answer_text = tokenizer.decode(answer[0], skip_special_tokens=True)  \n",
    "print(f\"Answer to question '{question}': {answer_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
